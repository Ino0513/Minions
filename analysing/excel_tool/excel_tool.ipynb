{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상단에 설정된 경로들\n",
    "PROJECT_DIR_PT = r\"C:\\Users\\ihman\\Desktop\\NextChip\\sechan\\JARVIS\\result\\pt\" # pt 경로\n",
    "DATA_PATH = r\"C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip.yaml\" # nextchip.yaml 경로\n",
    "PROJECT_DIR = r\"C:\\Users\\ihman\\Desktop\\NextChip\\sechan\\JARVIS\\result\"  # pt, val, csv 상위 경로\n",
    "LOG_DIR = os.path.join(PROJECT_DIR, \"val\") # val 경로\n",
    "CSV_PATH = os.path.join(PROJECT_DIR, \"csv_excel_file\", \"model_summary.csv\") # csv 경로\n",
    "EXCEL_PATH = os.path.join(PROJECT_DIR, \"csv_excel_file\", \"model_summary.xlsx\") # excel 경로\n",
    "\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "FPS = 160  # 예시 FPS 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate_model_val(model_path, data_path, project_dir, model_name):\n",
    "    # split_val 폴더 경로 생성\n",
    "    log_dir = os.path.join(project_dir, \"split_val\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_filename = Path(log_dir) / f\"{model_name}_val_log.txt\"\n",
    "    \n",
    "    # logger 생성 및 설정\n",
    "    logger = logging.getLogger(f\"{model_name}_val\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # 핸들러 초기화 및 추가 (덮어쓰기 모드로 설정)\n",
    "    handler = logging.FileHandler(log_filename, mode='w')\n",
    "    handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "    \n",
    "    # 동일 파일 핸들러 중복 추가 방지\n",
    "    if not any(isinstance(h, logging.FileHandler) and h.baseFilename == str(log_filename) for h in logger.handlers):\n",
    "        logger.addHandler(handler)\n",
    "    \n",
    "    # 모델 초기화 및 유효성 검사 (split='val')\n",
    "    model = YOLO(model_path)\n",
    "    metrics = model.val(\n",
    "        data=data_path,\n",
    "        project=project_dir,\n",
    "        name=model_name,\n",
    "        exist_ok=True,\n",
    "        split='val'\n",
    "    )\n",
    "    \n",
    "    # 유효성 검사 결과 로그 저장\n",
    "    logger.info(\"Validation results (val split): %s\", metrics)\n",
    "    \n",
    "    # 모델 파라미터 수 추출 및 로그 저장\n",
    "    model_summary_info = summary(model.model, verbose=0)\n",
    "    total_params = model_summary_info.total_params\n",
    "    logger.info(\"Model total parameters: %s\", total_params)\n",
    "    \n",
    "    # 전체 mAP50 값을 로그에 저장\n",
    "    overall_map50 = metrics.box.mean_results()[2]\n",
    "    logger.info(\"all mAP50 = %.4f\", overall_map50)\n",
    "    \n",
    "    # 클래스별 mAP50 값을 로그에 저장\n",
    "    class_names = metrics.names.values()\n",
    "    for i, name in enumerate(class_names):\n",
    "        map50 = metrics.box.class_result(i)[2]\n",
    "        logger.info(\"%s: mAP50 = %.4f\", name, map50)\n",
    "\n",
    "    print(f\"Val validation log saved in {log_filename}\")\n",
    "    return log_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV와 Excel 파일이 C:\\Users\\ihman\\Desktop\\NextChip\\sechan\\JARVIS\\result\\csv_excel_file\\model_summary.csv 및 C:\\Users\\ihman\\Desktop\\NextChip\\sechan\\JARVIS\\result\\csv_excel_file\\model_summary.xlsx에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "### txt 로그 파일 읽어서 csv, excel 파일 생성 ###\n",
    "\n",
    "def extract_logs(log_dir, csv_path, excel_path):\n",
    "    # split_test와 split_val 폴더의 모든 *_log.txt 파일 검색\n",
    "    test_log_files = glob.glob(f\"{log_dir}/split_test/*_test_log.txt\")\n",
    "    val_log_files = glob.glob(f\"{log_dir}/split_val/*_val_log.txt\")\n",
    "    data = []\n",
    "\n",
    "    # split_test 로그 파일 처리\n",
    "    for log_file in test_log_files:\n",
    "        with open(log_file, 'r') as file:\n",
    "            log_content = file.read()\n",
    "\n",
    "            model_name = Path(log_file).stem.replace(\"_test_log\", \"\")\n",
    "            params_match = re.search(r\"Model total parameters: (\\d+)\", log_content)\n",
    "            total_params = round(int(params_match.group(1)) / 1e6, 4) if params_match else None\n",
    "\n",
    "            class_map50 = {}\n",
    "            class_map50_matches = re.findall(r\"(\\w+): mAP50 = ([\\d.]+)\", log_content)\n",
    "            for match in class_map50_matches:\n",
    "                class_name, map50_value = match\n",
    "                class_map50[class_name] = round(float(map50_value), 4)\n",
    "\n",
    "            total_map50_match = re.search(r\"all mAP50 = ([\\d.]+)\", log_content)\n",
    "            test_map50 = round(float(total_map50_match.group(1)), 4) if total_map50_match else None\n",
    "\n",
    "            data.append({\n",
    "                'Model Name': model_name, \n",
    "                'Parameters (M)': total_params, \n",
    "                'Total mAP@0.5': test_map50, \n",
    "                'Val mAP@0.5': None, \n",
    "                **class_map50, \n",
    "                'FPS': FPS\n",
    "            })\n",
    "\n",
    "    # split_val 로그 파일 처리 (total mAP50 값만 저장)\n",
    "    for log_file in val_log_files:\n",
    "        with open(log_file, 'r') as file:\n",
    "            log_content = file.read()\n",
    "\n",
    "            model_name = Path(log_file).stem.replace(\"_val_log\", \"\")\n",
    "            total_map50_match = re.search(r\"all mAP50 = ([\\d.]+)\", log_content)\n",
    "            val_map50 = round(float(total_map50_match.group(1)), 4) if total_map50_match else None\n",
    "\n",
    "            # 해당 모델이 이미 data에 존재하는지 확인하여 업데이트 또는 추가\n",
    "            for entry in data:\n",
    "                if entry['Model Name'] == model_name:\n",
    "                    entry['Val mAP@0.5'] = val_map50  # Val split에서의 total mAP50 값만 저장\n",
    "                    break\n",
    "            else:\n",
    "                # 해당 모델이 data에 없으면 새 항목 추가 (Val split의 total mAP50 값만 저장)\n",
    "                data.append({ \n",
    "                    'Val mAP@0.5': val_map50, \n",
    "                })\n",
    "\n",
    "    # DataFrame 생성 및 저장\n",
    "    df = pd.DataFrame(data).drop_duplicates(subset=['Model Name'], keep='last')\n",
    "    df.to_csv(csv_path, index=False, float_format=\"%.4f\")\n",
    "    df.to_excel(excel_path, index=False, float_format=\"%.4f\")\n",
    "    print(f\"CSV와 Excel 파일이 {csv_path} 및 {excel_path}에 저장되었습니다.\")\n",
    "    return df\n",
    "\n",
    "df = extract_logs(LOG_DIR, CSV_PATH, EXCEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### graph 코드 인데 수정 해야됨 ###\n",
    "# Jupyter Notebook에서 그래프를 표시하도록 설정\n",
    "\n",
    "def plot_results_from_csv(data):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    unique_models = data['Model Name'].unique()\n",
    "    scatter_points = []\n",
    "\n",
    "    for model_name in unique_models:\n",
    "        model_data = data[data['Model Name'] == model_name]\n",
    "        fps_values = model_data['FPS']\n",
    "        map50_test = model_data['Total mAP@0.5']\n",
    "        map50_val = model_data['Val mAP@0.5']\n",
    "        params_values = model_data['Parameters (M)']\n",
    "        \n",
    "        scatter = plt.scatter(fps_values, map50_test, map50_val, s=params_values*250, alpha=0.6, label=model_name)\n",
    "        scatter_points.append((scatter, model_name))\n",
    "        \n",
    "        for fps, map50, params in zip(fps_values, map50_test, map50_val, params_values):\n",
    "            print(f\"Model: {model_name}, FPS: {fps}, Total mAP@0.5: {map50}, Parameters (M): {params}\")\n",
    "    \n",
    "    plt.xlabel(\"FPS\")\n",
    "    plt.ylabel(\"Total mAP@0.5\")\n",
    "    plt.title(\"Model Comparison - FPS vs. Total mAP@0.5 (Point Size by Parameters)\")\n",
    "    plt.grid()\n",
    "    \n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=scatter.get_facecolor()[0], markersize=10) for scatter, _ in scatter_points]\n",
    "    labels = [label for _, label in scatter_points]\n",
    "    plt.legend(handles, labels, title=\"Models\")\n",
    "    \n",
    "    plt.xlim(50, 300)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LOG_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ## 전체 모델에 대한 작업 수행 ###\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# for model_folder in os.listdir(PROJECT_DIR_PT):\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     model_path = os.path.join(PROJECT_DIR_PT, model_folder, \"weights\", \"best.pt\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 로그 추출 및 시각화\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m extract_logs(\u001b[43mLOG_DIR\u001b[49m, CSV_PATH, EXCEL_PATH)\n\u001b[0;32m     14\u001b[0m plot_results_from_csv(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LOG_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "## 전체 모델에 대한 작업 수행 ###\n",
    "for model_folder in os.listdir(PROJECT_DIR_PT):\n",
    "    model_path = os.path.join(PROJECT_DIR_PT, model_folder, \"weights\", \"best.pt\")\n",
    "    if os.path.isfile(model_path):\n",
    "        print(f\"\\n### Processing model: {model_folder} ###\\n\")\n",
    "        train_model(model_path, DATA_PATH, PROJECT_DIR_PT, model_folder, EPOCHS, BATCH_SIZE)\n",
    "        model_summary(model_path)\n",
    "        # 각각의 split에 대한 검증 수행\n",
    "        validate_model_test(model_path, DATA_PATH, LOG_DIR, model_folder)\n",
    "        validate_model_val(model_path, DATA_PATH, LOG_DIR, model_folder)\n",
    "        print(f\"\\n### finishing model : {model_folder} ###\\n\")\n",
    "\n",
    "# 로그 추출 및 시각화\n",
    "df = extract_logs(LOG_DIR, CSV_PATH, EXCEL_PATH)\n",
    "plot_results_from_csv(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
