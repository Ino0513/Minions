{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import method_onnx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_2211_gc-c3g_55_tv summary (fused): 300 layers, 8,934,270 parameters, 0 gradients, 25.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_55_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.3s, saved as '..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_55_tv.onnx' (34.2 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\final\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_55_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_55_tv.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_2211_gc-c3g_tv summary (fused): 282 layers, 8,551,914 parameters, 0 gradients, 25.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (16.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_tv.onnx' (32.8 MB)\n",
      "\n",
      "Export complete (1.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\final\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\final\\v8s_P2_2211_gc-c3g_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_2221_gc-c3g_tv summary (fused): 287 layers, 8,879,850 parameters, 0 gradients, 26.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\final\\v8s_P2_2221_gc-c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\final\\v8s_P2_2221_gc-c3g_tv.onnx' (34.0 MB)\n",
      "\n",
      "Export complete (1.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\final\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\final\\v8s_P2_2221_gc-c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\final\\v8s_P2_2221_gc-c3g_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_3322_BN-gc-c3g_50_tv summary (fused): 435 layers, 6,047,154 parameters, 0 gradients, 18.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\final\\v8s_P2_3322_BN-gc-c3g_50_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (11.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\final\\v8s_P2_3322_BN-gc-c3g_50_tv.onnx' (23.3 MB)\n",
      "\n",
      "Export complete (1.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\final\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\final\\v8s_P2_3322_BN-gc-c3g_50_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\final\\v8s_P2_3322_BN-gc-c3g_50_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_3322_gc-c3g_40_tv summary (fused): 302 layers, 6,939,947 parameters, 0 gradients, 21.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\final\\v8s_P2_3322_gc-c3g_40_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (13.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\final\\v8s_P2_3322_gc-c3g_40_tv.onnx' (26.6 MB)\n",
      "\n",
      "Export complete (1.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\final\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\final\\v8s_P2_3322_gc-c3g_40_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\final\\v8s_P2_3322_gc-c3g_40_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_3332_BN-gc-c3g_50_tv summary (fused): 451 layers, 6,057,938 parameters, 0 gradients, 18.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\final\\v8s_P2_3332_BN-gc-c3g_50_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (12.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.1s, saved as '..\\files\\weights_files\\final\\v8s_P2_3332_BN-gc-c3g_50_tv.onnx' (23.3 MB)\n",
      "\n",
      "Export complete (1.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\final\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\final\\v8s_P2_3332_BN-gc-c3g_50_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\final\\v8s_P2_3332_BN-gc-c3g_50_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_3332_gc-c3g_40_tv summary (fused): 307 layers, 7,156,475 parameters, 0 gradients, 21.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\final\\v8s_P2_3332_gc-c3g_40_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (14.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\final\\v8s_P2_3332_gc-c3g_40_tv.onnx' (27.5 MB)\n",
      "\n",
      "Export complete (1.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\final\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\final\\v8s_P2_3332_gc-c3g_40_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\final\\v8s_P2_3332_gc-c3g_40_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "method_onnx.onnx_all_by_dir('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method_onnx.onnx_allll(re_exp= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
