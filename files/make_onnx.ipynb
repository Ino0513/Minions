{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import method_onnx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 v5n vs v8n에 v5n_c2f_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_c2f_tv summary (fused): 195 layers, 2,748,594 parameters, 0 gradients, 7.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_c2f_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.7s, saved as '..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_c2f_tv.onnx' (10.6 MB)\n",
      "\n",
      "Export complete (1.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.1 v5n vs v8n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_c2f_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_c2f_tv.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.1 v5n vs v8n에 v5n_k3_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_k3_tv summary (fused): 211 layers, 2,181,538 parameters, 0 gradients, 5.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_k3_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_k3_tv.onnx' (8.5 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.1 v5n vs v8n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_k3_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_k3_tv.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.1 v5n vs v8n에 v5n_org_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_org_tv summary (fused): 211 layers, 2,182,834 parameters, 0 gradients, 5.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_org_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_org_tv.onnx' (8.5 MB)\n",
      "\n",
      "Export complete (0.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.1 v5n vs v8n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_org_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v5n_org_tv.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.1 v5n vs v8n에 v8n_c3_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_c3_tv summary (fused): 202 layers, 2,160,738 parameters, 0 gradients, 5.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_c3_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_c3_tv.onnx' (8.4 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.1 v5n vs v8n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_c3_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_c3_tv.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.1 v5n vs v8n에 v8n_k6_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_k6_tv summary (fused): 186 layers, 2,686,834 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_k6_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_k6_tv.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.1 v5n vs v8n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_k6_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_k6_tv.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.1 v5n vs v8n에 v8n_org_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_org_tv summary (fused): 186 layers, 2,685,538 parameters, 0 gradients, 6.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_org_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.6s, saved as '..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_org_tv.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.1 v5n vs v8n\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_org_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.1 v5n vs v8n\\v8n_org_tv.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.2 P2에 v8n_org_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_org summary (fused): 186 layers, 2,685,538 parameters, 0 gradients, 6.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.2 P2\\v8n_org_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.2 P2\\v8n_org_t.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.2 P2\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.2 P2\\v8n_org_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.2 P2\\v8n_org_t.onnx imgsz=384,640 data=yamls/nextchip.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.2 P2에 v8n_P2_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_P2_t summary (fused): 195 layers, 3,056,290 parameters, 0 gradients, 9.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.2 P2\\v8n_P2_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.2 P2\\v8n_P2_t.onnx' (11.8 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.2 P2\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.2 P2\\v8n_P2_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.2 P2\\v8n_P2_t.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_t.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.2 P2에 v8s_org_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_org_train summary (fused): 168 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.2 P2\\v8s_org_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\1.2 P2\\v8s_org_t.onnx' (42.6 MB)\n",
      "\n",
      "Export complete (1.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.2 P2\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.2 P2\\v8s_org_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.2 P2\\v8s_org_t.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.2 P2에 v8s_P2_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_p2_train summary (fused): 195 layers, 11,325,154 parameters, 0 gradients, 32.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.2 P2\\v8s_P2_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\1.2 P2\\v8s_P2_t.onnx' (43.3 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.2 P2\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.2 P2\\v8s_P2_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.2 P2\\v8s_P2_t.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v5n_2442_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_2442 summary (fused): 178 layers, 2,411,634 parameters, 0 gradients, 6.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v5n_2442_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.3 Bt\\v5n_2442_ta.onnx' (9.3 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_2442_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_2442_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v5n_4664_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_4664 summary (fused): 188 layers, 2,463,026 parameters, 0 gradients, 6.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v5n_4664_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.3 Bt\\v5n_4664_ta.onnx' (9.5 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_4664_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_4664_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v5n_6886_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_6886 summary (fused): 208 layers, 2,681,106 parameters, 0 gradients, 7.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v5n_6886_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.3 Bt\\v5n_6886_ta.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_6886_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_6886_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v8n_2442_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_2442 summary (fused): 158 layers, 2,904,226 parameters, 0 gradients, 7.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v8n_2442_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.3 Bt\\v8n_2442_ta.onnx' (11.2 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_2442_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_2442_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v8n_4664_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_4664 summary (fused): 168 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v8n_4664_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.3 Bt\\v8n_4664_ta.onnx' (11.6 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_4664_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_4664_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v8n_6886_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_6886 summary (fused): 188 layers, 3,442,498 parameters, 0 gradients, 9.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v8n_6886_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (6.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.6s, saved as '..\\files\\weights_files\\1.3 Bt\\v8n_6886_ta.onnx' (13.3 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_6886_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_6886_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.4 P2 Bt에 v8s_3963_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "8s_3963_tv summary (fused): 173 layers, 11,209,954 parameters, 0 gradients, 29.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_3963_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_3963_tv.onnx' (42.9 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_3963_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_3963_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.4 P2 Bt에 v8s_org_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_org_tv summary (fused): 168 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_org_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_org_tv.onnx' (42.6 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_org_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_org_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.4 P2 Bt에 v8s_P2_3963_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_3963_tv summary (fused): 200 layers, 11,407,202 parameters, 0 gradients, 33.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3963_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (22.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3963_tv.onnx' (43.7 MB)\n",
      "\n",
      "Export complete (1.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3963_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3963_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.4 P2 Bt에 v8s_P2_9963_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_9963_tv summary (fused): 210 layers, 11,448,290 parameters, 0 gradients, 35.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_9963_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (22.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_9963_tv.onnx' (43.8 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_9963_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_9963_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.4 P2 Bt에 v8s_P2_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 c c2f_tv summary (fused): 195 layers, 11,325,154 parameters, 0 gradients, 32.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_tv.onnx' (43.3 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.1 QE에 v5n_b8n5_2442_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_b8n5_2442 summary (fused): 170 layers, 2,627,938 parameters, 0 gradients, 6.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.1 QE\\v5n_b8n5_2442_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.1 QE\\v5n_b8n5_2442_ta.onnx' (10.2 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.1 QE\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.1 QE\\v5n_b8n5_2442_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.1 QE\\v5n_b8n5_2442_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.1 QE에 v5n_b8n5_4664_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_b8n5_4664 summary (fused): 180 layers, 2,731,826 parameters, 0 gradients, 7.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.1 QE\\v5n_b8n5_4664_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.1 QE\\v5n_b8n5_4664_ta.onnx' (10.6 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.1 QE\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.1 QE\\v5n_b8n5_4664_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.1 QE\\v5n_b8n5_4664_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.1 QE에 v5n_b8n5_6886_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_b8n5_6886 summary (fused): 200 layers, 3,167,506 parameters, 0 gradients, 8.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.1 QE\\v5n_b8n5_6886_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (6.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.1 QE\\v5n_b8n5_6886_ta.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.1 QE\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.1 QE\\v5n_b8n5_6886_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.1 QE\\v5n_b8n5_6886_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.1 QE에 v8n_b5n8_2442_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_b5n8_2442 summary (fused): 166 layers, 2,687,922 parameters, 0 gradients, 7.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.1 QE\\v8n_b5n8_2442_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.1 QE\\v8n_b5n8_2442_ta.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.1 QE\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.1 QE\\v8n_b5n8_2442_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.1 QE\\v8n_b5n8_2442_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.1 QE에 v8n_b5n8_4664_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_b5n8_4664 summary (fused): 176 layers, 2,738,018 parameters, 0 gradients, 7.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.1 QE\\v8n_b5n8_4664_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.1 QE\\v8n_b5n8_4664_ta.onnx' (10.6 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.1 QE\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.1 QE\\v8n_b5n8_4664_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.1 QE\\v8n_b5n8_4664_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.1 QE에 v8n_b5n8_6886_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_b5n8_6886 summary (fused): 196 layers, 2,956,098 parameters, 0 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.1 QE\\v8n_b5n8_6886_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.1 QE\\v8n_b5n8_6886_ta.onnx' (11.4 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.1 QE\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.1 QE\\v8n_b5n8_6886_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.1 QE\\v8n_b5n8_6886_ta.onnx imgsz=384,640 data=/content/drive/MyDrive/Nextchip_cfg/nextchip_colab_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF c c3g_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "nP2_B8 c c2f_N8 SF c c3g_t summary (fused): 260 layers, 2,542,962 parameters, 0 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3g_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.7s, saved as '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3g_t.onnx' (9.9 MB)\n",
      "\n",
      "Export complete (1.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 nP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3g_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3g_t.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_t.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF c c3_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "nP2_B8 c c2f_N8 SF c c3_t summary (fused): 205 layers, 2,790,050 parameters, 0 gradients, 8.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3_t.onnx' (10.8 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 nP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF c c3_t.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_t.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF gc c2f_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "nP2_B8 c c2f_N8 SF gc c2f_t summary (fused): 204 layers, 2,962,322 parameters, 0 gradients, 8.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c2f_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.6s, saved as '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c2f_t.onnx' (11.4 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 nP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c2f_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c2f_t.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_t.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF gc c3g_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "nP2_B8 c c2f_N8 SF gc c3g_t summary (fused): 269 layers, 2,448,994 parameters, 0 gradients, 7.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3g_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.7s, saved as '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3g_t.onnx' (9.5 MB)\n",
      "\n",
      "Export complete (1.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 nP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3g_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3g_t.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_t.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF gc c3_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "nP2_B8 c c2f_N8 SF gc c3_t summary (fused): 214 layers, 2,696,082 parameters, 0 gradients, 8.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3_t.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 nP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\nP2_B8 c c2f_N8 SF gc c3_t.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_t.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 nP2_c2f c3 c3g에 v8n_P2_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_P2_t summary (fused): 195 layers, 3,056,290 parameters, 0 gradients, 9.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\v8n_P2_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (6.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\v8n_P2_t.onnx' (11.8 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 nP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\v8n_P2_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 nP2_c2f c3 c3g\\v8n_P2_t.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_t.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF c c3g_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 SF c c3g_tv summary (fused): 273 layers, 9,240,778 parameters, 0 gradients, 26.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3g_tv.onnx' (35.4 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3g_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF c c3_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 SF c c3_tv summary (fused): 207 layers, 10,249,954 parameters, 0 gradients, 29.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (19.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3_tv.onnx' (39.3 MB)\n",
      "\n",
      "Export complete (1.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF c c3_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 gc c2f_tv summary (fused): 204 layers, 10,943,682 parameters, 0 gradients, 31.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c2f_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c2f_tv.onnx' (41.9 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c2f_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c2f_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF gc c3g_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 SF gc c3g_tv summary (fused): 282 layers, 8,859,306 parameters, 0 gradients, 25.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3g_tv.onnx' (34.0 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3g_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF gc c3_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 SF gc c3_tv summary (fused): 216 layers, 9,868,482 parameters, 0 gradients, 28.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (19.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3_tv.onnx' (37.8 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 SF gc c3_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 sP2_c2f c3 c3g에 v8s_P2_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 c c2f_tv summary (fused): 195 layers, 11,325,154 parameters, 0 gradients, 32.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\v8s_P2_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\v8s_P2_tv.onnx' (43.3 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\v8s_P2_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\v8s_P2_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v5n_org_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_org summary (fused): 211 layers, 2,182,834 parameters, 0 gradients, 5.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\org+org_add\\v5n_org_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.6s, saved as '..\\files\\weights_files\\org+org_add\\v5n_org_t.onnx' (8.5 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\org+org_add\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\org+org_add\\v5n_org_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\org+org_add\\v5n_org_t.onnx imgsz=384,640 data=yamls/nextchip.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v5n_org_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "YOLOv5 summary (fused): 193 layers, 2,504,114 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\org+org_add\\v5n_org_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\org+org_add\\v5n_org_ta.onnx' (9.7 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\org+org_add\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\org+org_add\\v5n_org_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\org+org_add\\v5n_org_ta.onnx imgsz=384,640 data=D:\\competition\\nextchip\\nextchip_shared\\nextchip.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v5s_org_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "YOLOv5 summary (fused): 193 layers, 9,113,858 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\org+org_add\\v5s_org_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.7s, saved as '..\\files\\weights_files\\org+org_add\\v5s_org_t.onnx' (34.9 MB)\n",
      "\n",
      "Export complete (1.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\org+org_add\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\org+org_add\\v5s_org_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\org+org_add\\v5s_org_t.onnx imgsz=384,640 data=D:\\competition\\nextchip\\nextchip_shared\\nextchip.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v8n_org_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_org summary (fused): 186 layers, 2,685,538 parameters, 0 gradients, 6.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\org+org_add\\v8n_org_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.6s, saved as '..\\files\\weights_files\\org+org_add\\v8n_org_t.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\org+org_add\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\org+org_add\\v8n_org_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\org+org_add\\v8n_org_t.onnx imgsz=384,640 data=yamls/nextchip.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v8n_org_ta은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_org summary (fused): 186 layers, 2,685,538 parameters, 0 gradients, 6.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\org+org_add\\v8n_org_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\org+org_add\\v8n_org_ta.onnx' (10.4 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\org+org_add\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\org+org_add\\v8n_org_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\org+org_add\\v8n_org_ta.onnx imgsz=384,640 data=yamls/nextchip_add.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v8s_org_t은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_org summary (fused): 186 layers, 9,829,986 parameters, 0 gradients, 23.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\org+org_add\\v8s_org_t.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (19.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\org+org_add\\v8s_org_t.onnx' (37.6 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\org+org_add\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\org+org_add\\v8s_org_t.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\org+org_add\\v8s_org_t.onnx imgsz=384,640 data=yamls/nextchip.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v8s_org_tv은 이미 있는데 교체될거양 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_org_tv summary (fused): 168 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\org+org_add\\v8s_org_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as '..\\files\\weights_files\\org+org_add\\v8s_org_tv.onnx' (42.6 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\org+org_add\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\org+org_add\\v8s_org_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\org+org_add\\v8s_org_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "method_onnx.onnx_allll(re_exp= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
