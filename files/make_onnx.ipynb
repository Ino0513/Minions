{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import method_onnx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 v5n vs v8n에 v5n_c2f_tv은 이미 잇성 히히\n",
      "1.1 v5n vs v8n에 v5n_k3_tv은 이미 잇성 히히\n",
      "1.1 v5n vs v8n에 v5n_org_tv은 이미 잇성 히히\n",
      "1.1 v5n vs v8n에 v8n_c3_tv은 이미 잇성 히히\n",
      "1.1 v5n vs v8n에 v8n_k6_tv은 이미 잇성 히히\n",
      "1.1 v5n vs v8n에 v8n_org_tv은 이미 잇성 히히\n",
      "1.2 P2에 v8n_org_t은 이미 잇성 히히\n",
      "1.2 P2에 v8n_P2_t은 이미 잇성 히히\n",
      "1.2 P2에 v8s_org_t은 이미 잇성 히히\n",
      "1.2 P2에 v8s_P2_t은 이미 잇성 히히\n",
      "1.3 Bt에 v5n_1111_ta은 이미 잇성 히히\n",
      "1.3 Bt에 v5n_1221_ta은 이미 잇성 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v5n_2222_ta summary (fused): 216 layers, 2,308,434 parameters, 0 gradients, 5.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v5n_2222_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (4.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.6s, saved as '..\\files\\weights_files\\1.3 Bt\\v5n_2222_ta.onnx' (9.0 MB)\n",
      "\n",
      "Export complete (0.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_2222_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v5n_2222_ta.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_ta.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v5n_2332_ta은 이미 잇성 히히\n",
      "1.3 Bt에 v8n_1111_ta은 이미 잇성 히히\n",
      "1.3 Bt에 v8n_1221_ta은 이미 잇성 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_2222_ta summary (fused): 196 layers, 3,018,626 parameters, 0 gradients, 7.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.3 Bt\\v8n_2222_ta.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.5s, saved as '..\\files\\weights_files\\1.3 Bt\\v8n_2222_ta.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (0.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.3 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_2222_ta.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.3 Bt\\v8n_2222_ta.onnx imgsz=384,640 data=C:\\Users\\ihman\\Desktop\\NextChip\\dataset\\nextchip_ta.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.3 Bt에 v8n_2332_ta은 이미 잇성 히히\n",
      "1.4 P2 Bt에 v8s_1321_tv은 이미 잇성 히히\n",
      "1.4 P2 Bt에 v8s_org_tv은 이미 잇성 히히\n",
      "1.4 P2 Bt에 v8s_P2_1321_tv은 이미 잇성 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_2221_tv summary (fused): 200 layers, 11,345,698 parameters, 0 gradients, 33.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_2221_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_2221_tv.onnx' (43.4 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_2221_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_2221_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_3221_tv summary (fused): 205 layers, 11,366,242 parameters, 0 gradients, 34.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3221_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (21.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3221_tv.onnx' (43.5 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3221_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_3221_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.4 P2 Bt에 v8s_P2_3321_tv은 이미 잇성 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8s_P2_4221_tv summary (fused): 210 layers, 11,386,786 parameters, 0 gradients, 35.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_4221_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (22.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_4221_tv.onnx' (43.6 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\1.4 P2 Bt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_4221_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\1.4 P2 Bt\\v8s_P2_4221_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "1.4 P2 Bt에 v8s_P2_tv은 이미 잇성 히히\n",
      "2.1 QE에 v5n_b8n5_2442_ta은 이미 잇성 히히\n",
      "2.1 QE에 v5n_b8n5_4664_ta은 이미 잇성 히히\n",
      "2.1 QE에 v5n_b8n5_6886_ta은 이미 잇성 히히\n",
      "2.1 QE에 v8n_b5n8_2442_ta은 이미 잇성 히히\n",
      "2.1 QE에 v8n_b5n8_4664_ta은 이미 잇성 히히\n",
      "2.1 QE에 v8n_b5n8_6886_ta은 이미 잇성 히히\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF c c3g_t은 이미 잇성 히히\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF c c3_t은 이미 잇성 히히\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF gc c2f_t은 이미 잇성 히히\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF gc c3g_t은 이미 잇성 히히\n",
      "2.2 nP2_c2f c3 c3g에 nP2_B8 c c2f_N8 SF gc c3_t은 이미 잇성 히히\n",
      "2.2 nP2_c2f c3 c3g에 v8n_P2_t은 이미 잇성 히히\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF c c3g_tv은 이미 잇성 히히\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF c c3_tv은 이미 잇성 히히\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF gc c2f_tv은 이미 잇성 히히\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF gc c3g_tv은 이미 잇성 히히\n",
      "2.2 sP2_c2f c3 c3g에 sP2_B8 c c2f_N8 SF gc c3_tv은 이미 잇성 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 c c3g_tv summary (fused): 260 layers, 9,260,162 parameters, 0 gradients, 27.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST c c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (18.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST c c3g_tv.onnx' (35.5 MB)\n",
      "\n",
      "Export complete (1.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST c c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST c c3g_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 gc c3g_tv summary (fused): 269 layers, 8,878,690 parameters, 0 gradients, 26.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST gc c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST gc c3g_tv.onnx' (34.0 MB)\n",
      "\n",
      "Export complete (1.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.2 sP2_c2f c3 c3g\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST gc c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.2 sP2_c2f c3 c3g\\sP2_B8 c c2f_N8 ST gc c3g_tv.onnx imgsz=384,640 data=/content/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "2.2 sP2_c2f c3 c3g에 v8s_P2_tv은 이미 잇성 히히\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "v8n_p1p2_99663 summary (fused): 357 layers, 2,559,644 parameters, 0 gradients, 9.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\2.3 P1P2\\v8n_p1p2_99663_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\2.3 P1P2\\v8n_p1p2_99663_tv.onnx' (9.9 MB)\n",
      "\n",
      "Export complete (1.1s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\2.3 P1P2\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\2.3 P1P2\\v8n_p1p2_99663_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\2.3 P1P2\\v8n_p1p2_99663_tv.onnx imgsz=384,640 data=D:\\competition\\nextchip\\train_txt\\nextchip.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 SF c c3g_tv_relu6 summary (fused): 273 layers, 9,240,778 parameters, 0 gradients, 26.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\3.1 activation\\sP2_relu6_B8 c c2f_N8 SF c c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as '..\\files\\weights_files\\3.1 activation\\sP2_relu6_B8 c c2f_N8 SF c c3g_tv.onnx' (35.4 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\3.1 activation\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\3.1 activation\\sP2_relu6_B8 c c2f_N8 SF c c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\3.1 activation\\sP2_relu6_B8 c c2f_N8 SF c c3g_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.35  Python-3.11.8 torch-2.5.0+cpu CPU (13th Gen Intel Core(TM) i3-1315U)\n",
      "sP2_B8 c c2f_N8 SF c c3g_tv_relu summary (fused): 273 layers, 9,240,778 parameters, 0 gradients, 26.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '..\\files\\weights_files\\3.1 activation\\sP2_relu_B8 c c2f_N8 SF c c3g_tv.pt' with input shape (1, 3, 384, 640) BCHW and output shape(s) (1, 10, 5040) (17.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as '..\\files\\weights_files\\3.1 activation\\sP2_relu_B8 c c2f_N8 SF c c3g_tv.onnx' (35.4 MB)\n",
      "\n",
      "Export complete (1.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\weights_files\\3.1 activation\u001b[0m\n",
      "Predict:         yolo predict task=detect model=..\\files\\weights_files\\3.1 activation\\sP2_relu_B8 c c2f_N8 SF c c3g_tv.onnx imgsz=384,640 int8 \n",
      "Validate:        yolo val task=detect model=..\\files\\weights_files\\3.1 activation\\sP2_relu_B8 c c2f_N8 SF c c3g_tv.onnx imgsz=384,640 data=/content/Minions/colab/cfg/colab_tv.yaml int8 WARNING  non-PyTorch val requires square images, 'imgsz=[384, 640]' will not work. Use export 'imgsz=640' if val is required.\n",
      "Visualize:       https://netron.app\n",
      "org+org_add에 v5n_org_t은 이미 잇성 히히\n",
      "org+org_add에 v5n_org_ta은 이미 잇성 히히\n",
      "org+org_add에 v5s_org_t은 이미 잇성 히히\n",
      "org+org_add에 v8n_org_t은 이미 잇성 히히\n",
      "org+org_add에 v8n_org_ta은 이미 잇성 히히\n",
      "org+org_add에 v8s_org_t은 이미 잇성 히히\n",
      "org+org_add에 v8s_org_tv은 이미 잇성 히히\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] 디렉터리 이름이 올바르지 않습니다: '../files/weights_files/yolov5-bifpn.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmethod_onnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx_allll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mre_exp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\method_onnx.py:57\u001b[0m, in \u001b[0;36monnx_allll\u001b[1;34m(re_exp)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[43monnx_all_by_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre_exp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mre_exp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ino\\Desktop\\NextChip\\Minions_git\\files\\method_onnx.py:44\u001b[0m, in \u001b[0;36monnx_all_by_dir\u001b[1;34m(dir_name, re_exp)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21monnx_all_by_dir\u001b[39m(dir_name, re_exp\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 44\u001b[0m     name_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m exp_name \u001b[38;5;129;01min\u001b[39;00m name_list:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(exp_name[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] 디렉터리 이름이 올바르지 않습니다: '../files/weights_files/yolov5-bifpn.pt'"
     ]
    }
   ],
   "source": [
    "method_onnx.onnx_allll(re_exp= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
