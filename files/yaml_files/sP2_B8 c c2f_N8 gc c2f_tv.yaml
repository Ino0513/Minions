# Ultralytics YOLO 🚀, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 6 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  # n: [0.33, 0.25, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024] # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  # m: [0.67, 0.75, 768] # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  # l: [1.00, 1.00, 512] # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  # x: [1.00, 1.25, 512] # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs


# YOLOv8 v6.0 backbone
# - [-1, 1, Conv, [64, 3, 2]]
# -1 : 이전 레이어로부터의 입력 위치를 지정
# 1 : 모듈이 몇번 반복되는지
# Conv : 적용할 레이어의 종류를 정의
# [64, 3, 2] : 모듈에 전달되는 인자
# => [출력 채널 수(c2), 커널 크기, stride]


# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2  => input: (32, 3, 640, 640) / output: (32, 64, 320, 320)
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4 => input: (32, 64, 320, 320) / output: (32, 128, 160, 160)
  - [-1, 3, C2f, [128, True]] # => input: (32, 128, 160, 160) / output: (32, 128, 160, 160)
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8 => input: (32, 128, 160, 160) / output: (32, 256, 80, 80)
  - [-1, 6, C2f, [256, True]] # => input: (32, 256, 80, 80) / output: (32, 256, 80, 80)
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16  => input: (32, 256, 80, 80) / output: (32, 512, 40, 40)
  - [-1, 6, C2f, [512, True]] # => input: (32, 512, 40, 40) / output: (32, 512, 40, 40)
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32 => input: (32, 512, 40, 40) / output: (32, 1024, 20, 20)
  - [-1, 3, C2f, [1024, True]] #  => input: (32, 1024, 20, 20) / output: (32, 1024, 20, 20)
  - [-1, 1, SPPF, [1024, 5]] # 9  => input: (32, 1024, 20, 20) / output: (32, 1024, 20, 20)
# - [-1, 1, SE, []] SE Attention 넣어서 하기

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # => input: (32, 1024, 20, 20) / output: (32, 1024, 40, 40)
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4 => input: (32, 1024, 40, 40) / output: (32, 1536, 40, 40)
  - [-1, 3, C2f, [512]] # 12  => input: (32, 1536, 40, 40) / output: (32, 512, 40, 40)

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # => input: (512, 40, 40) / output: (512, 80, 80)
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3   => input: (512, 80, 80) / output: (768, 80, 80)
  - [-1, 3, C2f, [256]] # 15                   => input: (768, 80, 80) / output: (256, 80, 80)

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # => input: (256, 80, 80) / output: (256, 160, 160)
  - [[-1, 2], 1, Concat, [1]] # cat backbone P3   => input: (256, 160, 160) / output: (384, 160, 160)
  - [-1, 3, C2f, [128]] # 18 (P2/4-more small)         => input: (384, 160, 160) / output: (128, 160, 160)

  - [-1, 1, GhostConv, [128, 3, 2]] #             => input: (128, 160, 160) / output: (256, 80, 80)
  - [[-1, 15], 1, Concat, [1]] # cat head P4      => input: (256, 80, 80) / output: (512, 80, 80)
  - [-1, 3, C2f, [256]] # 21 (P3/8-small)       => input: (512, 80, 80) / output: (256, 80, 80)

  - [-1, 1, GhostConv, [256, 3, 2]] #             => input: (256, 80, 80) / output: (512, 40, 40)
  - [[-1, 12], 1, Concat, [1]] # cat head P4      => input: (512, 40, 40) / output: (1024, 40, 40)
  - [-1, 3, C2f, [512]] # 24 (P4/16-medium)   => input: (1024, 40, 40) / output: (512, 40, 40)

  - [-1, 1, GhostConv, [512, 3, 2]] #            => input: (512, 40, 40) / output:  (1024, 20, 20)
  - [[-1, 9], 1, Concat, [1]] # cat head P5       => input: (1024, 20, 20) / output: (2048, 20, 20)
  - [-1, 3, C2f, [1024]] # 27 (P5/32-large)   => input: (2048, 20, 20) / output: (1024, 20, 20)

  - [[21, 24, 27], 1, Detect, [nc]] # Detect(P3, P4, P5)
