{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO(r\"D:\\competition\\yolo-V8\\runs\\detect\\train\\weights\\best.pt\")\n",
    "model.to('cuda')\n",
    "\n",
    "# 데이터셋 경로\n",
    "# data_path = r\"C:\\code\\nextchip.yaml\"\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 양자화 준비\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "torch.quantization.prepare(model.model, inplace=True)\n",
    "\n",
    "# 캘리브레이션 데이터로 모델 실행\n",
    "dummy_input = torch.randn(1, 3, 640, 640).to('cuda')\n",
    "model.model(dummy_input)\n",
    "\n",
    "# 모델 양자화\n",
    "torch.quantization.convert(model.model, inplace=True)\n",
    "\n",
    "# 양자화된 모델을 ONNX로 내보내기 (ONNX 변환 시 모델은 CPU로 이동 필요)\n",
    "dummy_input_cpu = dummy_input.to('cpu')\n",
    "model.model.to('cpu')  # ONNX로 내보낼 때는 CPU로 모델 전환\n",
    "\n",
    "# 양자화된 모델을 ONNX로 내보내기\n",
    "torch.onnx.export(model.model,\n",
    "                  dummy_input_cpu,\n",
    "                  r\"D:\\competition\\yolov8_onnx\\yolov8s_quantinized.onnx\",\n",
    "                  export_params=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# ONNX 모델 로드\n",
    "onnx_model_path = r\"C:\\code\\onnx-modifier\\modified_onnx\\modified_yolov5s_simplified.onnx\"\n",
    "quantized_model_path = r\"C:\\code\\yolov5s_onnx\\yolov5s_quantized.onnx\"\n",
    "\n",
    "# 양자화 적용 (INT8)\n",
    "quantize_dynamic(onnx_model_path, quantized_model_path, weight_type=QuantType.QInt8)\n",
    "\n",
    "print(f\"양자화된 모델이 저장되었습니다: {quantized_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper, shape_inference\n",
    "\n",
    "# ONNX 모델 로드\n",
    "onnx_model_path = r\"C:\\code\\yolov8s_onnx\\yolov8s.onnx\"\n",
    "modified_model_path = r\"C:\\code\\yolov8s_onnx\\modified_yolov8s.onnx\"\n",
    "\n",
    "# 모델 로드\n",
    "model = onnx.load(onnx_model_path)\n",
    "\n",
    "# ConvInteger와 DynamicQuantizeLinear 제거\n",
    "nodes_to_remove = []\n",
    "for node in model.graph.node:\n",
    "    if node.op_type in [\"ConvInteger\", \"DynamicQuantizeLinear\"]:\n",
    "        nodes_to_remove.append(node)\n",
    "\n",
    "# 모델 그래프에서 해당 노드 제거\n",
    "for node in nodes_to_remove:\n",
    "    model.graph.node.remove(node)\n",
    "\n",
    "# 모델에 다른 필요한 변경이 있으면 여기에서 수행\n",
    "\n",
    "# 모델 저장 전 shape_inference 수행\n",
    "model = shape_inference.infer_shapes(model)\n",
    "\n",
    "# 수정된 모델 저장\n",
    "onnx.save(model, modified_model_path)\n",
    "\n",
    "print(f\"수정된 모델이 저장되었습니다: {modified_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.quantization\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "# from torch.utils.data import DataLoader\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# # 1. 이미 학습된 모델 로드\n",
    "# model = YOLO(r'C:\\code\\yolov8_onnx\\best.pt')  # 학습된 모델 로드\n",
    "\n",
    "# # 새로운 YAML 파일 경로 설정\n",
    "# new_yaml_path = r\"C:\\code\\nextchip.yaml\"\n",
    "# model.overrides['data'] = new_yaml_path\n",
    "\n",
    "# model.eval()  # 평가 모드로 전환\n",
    "\n",
    "# # 2. 모델 양자화 준비\n",
    "# model.qconfig = torch.quantization.get_default_qconfig('fbgemm')  # 또는 'qnnpack'\n",
    "# torch.quantization.prepare(model, inplace=True)\n",
    "\n",
    "# # 3. 성능 비교를 위한 데이터 준비\n",
    "# # CIFAR-10 데이터셋을 사용하여 테스트 데이터셋 준비\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32, 32)),  # 모델 입력 크기에 맞게 조정\n",
    "#     transforms.ToTensor(),  # Tensor로 변환\n",
    "# ])\n",
    "# test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# # 4. 원본 모델 성능 평가\n",
    "# original_correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         original_output = model(images)  # 원본 모델 예측\n",
    "#         _, predicted = torch.max(original_output.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         original_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# # 정확도 계산\n",
    "# original_accuracy = 100 * original_correct / total\n",
    "# print(f\"Original Model Accuracy: {original_accuracy:.2f}%\")\n",
    "\n",
    "# # 5. 양자화\n",
    "# torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "# # 6. 양자화된 모델 성능 평가\n",
    "# quantized_correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         quantized_output = model(images)  # 양자화된 모델 예측\n",
    "#         _, predicted = torch.max(quantized_output.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         quantized_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# # 정확도 계산\n",
    "# quantized_accuracy = 100 * quantized_correct / total\n",
    "# print(f\"Quantized Model Accuracy: {quantized_accuracy:.2f}%\")\n",
    "\n",
    "# # 7. 성능 비교 출력\n",
    "# print(f\"Original Model Accuracy: {original_accuracy:.2f}%\")\n",
    "# print(f\"Quantized Model Accuracy: {quantized_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# PyTorch 모델 로드\n",
    "model = YOLO(r\"C:\\code\\yolov8_onnx\\yolov8s.pt\")\n",
    "\n",
    "# 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 더미 입력 생성 (ONNX 변환을 위한 입력 샘플)\n",
    "dummy_input = torch.randn(1, 3, 640, 640)\n",
    "\n",
    "# PyTorch 모델을 ONNX 형식으로 내보내기\n",
    "onnx_model_path = r\"C:\\code\\yolov8s_onnx\\yolov8s.onnx\"\n",
    "torch.onnx.export(model.model,  # PyTorch 모델 내부 구조를 넘겨줘야 함\n",
    "                  dummy_input,\n",
    "                  onnx_model_path,\n",
    "                  export_params=True,\n",
    "                  opset_version=13,\n",
    "                  do_constant_folding=True,  # 상수 폴딩 최적화\n",
    "                  input_names=[\"input\"],\n",
    "                  output_names=[\"output\"])\n",
    "\n",
    "print(f\"ONNX 모델이 저장되었습니다: {onnx_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
